{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangyan/workspace/kaggle_qa/venv/lib/python3.6/site-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4749f7add73144c7b5ee38c98c352412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangyan/workspace/kaggle_qa/venv/lib/python3.6/site-packages/ipykernel_launcher.py:47: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e67f81322843288f4d3b884c0769b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def build_train(train_path, n_rows=200000, sampling_rate=15):\n",
    "    with open(train_path) as f:\n",
    "        processed_rows = []\n",
    "\n",
    "        for i in tqdm(range(n_rows)):\n",
    "            line = f.readline()\n",
    "            if not line:\n",
    "                break\n",
    "\n",
    "            line = json.loads(line)\n",
    "\n",
    "            text = line['document_text'].split(' ')\n",
    "            question = line['question_text']\n",
    "            annotations = line['annotations'][0]\n",
    "\n",
    "            for i, candidate in enumerate(line['long_answer_candidates']):\n",
    "                label = i == annotations['long_answer']['candidate_index']\n",
    "\n",
    "                start = candidate['start_token']\n",
    "                end = candidate['end_token']\n",
    "\n",
    "                if label or (i % sampling_rate == 0):\n",
    "                    processed_rows.append({\n",
    "                        'text': \" \".join(text[start:end]),\n",
    "                        'is_long_answer': label,\n",
    "                        'question': question,\n",
    "                        'annotation_id': annotations['annotation_id']\n",
    "                    })\n",
    "\n",
    "        train = pd.DataFrame(processed_rows)\n",
    "        \n",
    "        return train\n",
    "    \n",
    "def build_test(test_path):\n",
    "    with open(test_path) as f:\n",
    "        processed_rows = []\n",
    "\n",
    "        for line in tqdm(f):\n",
    "            line = json.loads(line)\n",
    "\n",
    "            text = line['document_text'].split(' ')\n",
    "            question = line['question_text']\n",
    "            example_id = line['example_id']\n",
    "\n",
    "            for candidate in line['long_answer_candidates']:\n",
    "                start = candidate['start_token']\n",
    "                end = candidate['end_token']\n",
    "\n",
    "                processed_rows.append({\n",
    "                    'text': \" \".join(text[start:end]),\n",
    "                    'question': question,\n",
    "                    'example_id': example_id,\n",
    "                    'sequence': f'{start}:{end}'\n",
    "\n",
    "                })\n",
    "\n",
    "        test = pd.DataFrame(processed_rows)\n",
    "    \n",
    "    return test\n",
    "\n",
    "\n",
    "directory = '../input/'\n",
    "train_path = directory + 'simplified-nq-train.jsonl'\n",
    "test_path = directory + 'simplified-nq-test.jsonl'\n",
    "\n",
    "train = build_train(train_path)\n",
    "test = build_test(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_long_answer</th>\n",
       "      <th>question</th>\n",
       "      <th>annotation_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;Table&gt; &lt;Tr&gt; &lt;Td&gt; &lt;/Td&gt; &lt;Td&gt; ( hide ) This art...</td>\n",
       "      <td>False</td>\n",
       "      <td>which is the most common use of opt-in e-mail ...</td>\n",
       "      <td>593165450220027640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;Tr&gt; &lt;Td&gt; &lt;Ul&gt; &lt;Li&gt; Pay - per - click &lt;/Li&gt; &lt;L...</td>\n",
       "      <td>False</td>\n",
       "      <td>which is the most common use of opt-in e-mail ...</td>\n",
       "      <td>593165450220027640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;P&gt; Email marketing has evolved rapidly alongs...</td>\n",
       "      <td>False</td>\n",
       "      <td>which is the most common use of opt-in e-mail ...</td>\n",
       "      <td>593165450220027640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;Li&gt; Advertisers can reach substantial numbers...</td>\n",
       "      <td>False</td>\n",
       "      <td>which is the most common use of opt-in e-mail ...</td>\n",
       "      <td>593165450220027640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;P&gt; A common example of permission marketing i...</td>\n",
       "      <td>True</td>\n",
       "      <td>which is the most common use of opt-in e-mail ...</td>\n",
       "      <td>593165450220027640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;P&gt; The CAN - SPAM Act of 2003 was passed by C...</td>\n",
       "      <td>False</td>\n",
       "      <td>which is the most common use of opt-in e-mail ...</td>\n",
       "      <td>593165450220027640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;Table&gt; &lt;Tr&gt; &lt;Th_colspan=\"2\"&gt; Tracy McConnell ...</td>\n",
       "      <td>False</td>\n",
       "      <td>how i.met your mother who is the mother</td>\n",
       "      <td>12034874153783787365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;P&gt; Tracy McConnell , better known as `` The M...</td>\n",
       "      <td>True</td>\n",
       "      <td>how i.met your mother who is the mother</td>\n",
       "      <td>12034874153783787365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;P&gt; In `` Bass Player Wanted '' , the Mother p...</td>\n",
       "      <td>False</td>\n",
       "      <td>how i.met your mother who is the mother</td>\n",
       "      <td>12034874153783787365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;Table&gt; &lt;Tr&gt; &lt;Td&gt; Part of a series on &lt;/Td&gt; &lt;/...</td>\n",
       "      <td>False</td>\n",
       "      <td>what type of fertilisation takes place in humans</td>\n",
       "      <td>10527123009892725162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  is_long_answer  \\\n",
       "0  <Table> <Tr> <Td> </Td> <Td> ( hide ) This art...           False   \n",
       "1  <Tr> <Td> <Ul> <Li> Pay - per - click </Li> <L...           False   \n",
       "2  <P> Email marketing has evolved rapidly alongs...           False   \n",
       "3  <Li> Advertisers can reach substantial numbers...           False   \n",
       "4  <P> A common example of permission marketing i...            True   \n",
       "5  <P> The CAN - SPAM Act of 2003 was passed by C...           False   \n",
       "6  <Table> <Tr> <Th_colspan=\"2\"> Tracy McConnell ...           False   \n",
       "7  <P> Tracy McConnell , better known as `` The M...            True   \n",
       "8  <P> In `` Bass Player Wanted '' , the Mother p...           False   \n",
       "9  <Table> <Tr> <Td> Part of a series on </Td> </...           False   \n",
       "\n",
       "                                            question         annotation_id  \n",
       "0  which is the most common use of opt-in e-mail ...    593165450220027640  \n",
       "1  which is the most common use of opt-in e-mail ...    593165450220027640  \n",
       "2  which is the most common use of opt-in e-mail ...    593165450220027640  \n",
       "3  which is the most common use of opt-in e-mail ...    593165450220027640  \n",
       "4  which is the most common use of opt-in e-mail ...    593165450220027640  \n",
       "5  which is the most common use of opt-in e-mail ...    593165450220027640  \n",
       "6            how i.met your mother who is the mother  12034874153783787365  \n",
       "7            how i.met your mother who is the mother  12034874153783787365  \n",
       "8            how i.met your mother who is the mother  12034874153783787365  \n",
       "9   what type of fertilisation takes place in humans  10527123009892725162  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate, Masking\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, GlobalMaxPooling1D, Dropout\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_text_and_questions(train, test, tokenizer):\n",
    "    train_text = tokenizer.texts_to_sequences(train.text.values)\n",
    "    train_questions = tokenizer.texts_to_sequences(train.question.values)\n",
    "    test_text = tokenizer.texts_to_sequences(test.text.values)\n",
    "    test_questions = tokenizer.texts_to_sequences(test.question.values)\n",
    "    \n",
    "    train_text = sequence.pad_sequences(train_text, maxlen=500)\n",
    "    train_questions = sequence.pad_sequences(train_questions)\n",
    "    test_text = sequence.pad_sequences(test_text, maxlen=500)\n",
    "    test_questions = sequence.pad_sequences(test_questions)\n",
    "    \n",
    "    return train_text, train_questions, test_text, test_questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练出一个Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangyan/workspace/kaggle_qa/venv/lib/python3.6/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca25efb909dd4f06ae3f5ffe9df913b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = text.Tokenizer(lower=False, num_words=80000) #取前80000个单词\n",
    "\n",
    "for text in tqdm([train.text, test.text, train.question, test.question]):\n",
    "    tokenizer.fit_on_texts(text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train.is_long_answer.astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, train_questions, test_text, test_questions = compute_text_and_questions(train, test, tokenizer)\n",
    "del train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 词向量\n",
    "\n",
    "这里使用的是fasttext做权重，其他的也可以\n",
    "https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M-subword.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = directory+'crawl-300d-2M-subword.bin'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_embedding_matrix(tokenizer, path):\n",
    "    embedding_matrix = np.zeros((tokenizer.num_words + 1, 300))\n",
    "    ft_model = fasttext.load_model(path)\n",
    "\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i >= tokenizer.num_words - 1:\n",
    "            break\n",
    "        embedding_matrix[i] = ft_model.get_word_vector(word)\n",
    "    \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = build_embedding_matrix(tokenizer, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(embedding_matrix):\n",
    "    embedding = Embedding(\n",
    "        *embedding_matrix.shape, # 这里相当于输入了一个元组，因为inputdim需要指定。a=(1,2,2)  fun(*a) 相当于f((1,2,3))\n",
    "        weights=[embedding_matrix], \n",
    "        trainable=False,\n",
    "        mask_zero=True\n",
    "    )\n",
    "    \n",
    "    q_in = Input(shape=(None,))\n",
    "    q = embedding(q_in)\n",
    "    q = SpatialDropout1D(0.2)(q)\n",
    "    q = Bidirectional(LSTM(100, return_sequences=True))(q)\n",
    "    q = GlobalMaxPooling1D()(q)\n",
    "    \n",
    "    \n",
    "    t_in = Input(shape=(None,))\n",
    "    t = embedding(t_in)\n",
    "    t = SpatialDropout1D(0.2)(t)\n",
    "    t = Bidirectional(LSTM(150, return_sequences=True))(t)\n",
    "    t = GlobalMaxPooling1D()(t)\n",
    "    \n",
    "    hidden = concatenate([q, t])\n",
    "    hidden = Dense(300, activation='relu')(hidden)\n",
    "    hidden = Dropout(0.5)(hidden)\n",
    "    hidden = Dense(300, activation='relu')(hidden)\n",
    "    hidden = Dropout(0.5)(hidden)\n",
    "    \n",
    "    out1 = Dense(1, activation='sigmoid')(hidden)\n",
    "    \n",
    "    model = Model(inputs=[t_in, q_in], outputs=out1)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /Users/zhangyan/workspace/kaggle_qa/venv/lib/python3.6/site-packages (2.3.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /Users/zhangyan/workspace/kaggle_qa/venv/lib/python3.6/site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /Users/zhangyan/workspace/kaggle_qa/venv/lib/python3.6/site-packages (from keras) (1.3.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /Users/zhangyan/workspace/kaggle_qa/venv/lib/python3.6/site-packages (from keras) (1.13.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /Users/zhangyan/workspace/kaggle_qa/venv/lib/python3.6/site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: h5py in /Users/zhangyan/workspace/kaggle_qa/venv/lib/python3.6/site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /Users/zhangyan/workspace/kaggle_qa/venv/lib/python3.6/site-packages (from keras) (1.17.4)\n",
      "Requirement already satisfied: pyyaml in /Users/zhangyan/workspace/kaggle_qa/venv/lib/python3.6/site-packages (from keras) (5.1.2)\n",
      "Requirement already satisfied: scikit-learn in /Users/zhangyan/workspace/kaggle_qa/venv/lib/python3.6/site-packages (0.21.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/zhangyan/workspace/kaggle_qa/venv/lib/python3.6/site-packages (from scikit-learn) (0.14.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /Users/zhangyan/workspace/kaggle_qa/venv/lib/python3.6/site-packages (from scikit-learn) (1.3.3)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /Users/zhangyan/workspace/kaggle_qa/venv/lib/python3.6/site-packages (from scikit-learn) (1.17.4)\n",
      "Collecting pydot\n",
      "  Using cached https://files.pythonhosted.org/packages/33/d1/b1479a770f66d962f545c2101630ce1d5592d90cb4f083d38862e93d16d2/pydot-1.4.1-py2.py3-none-any.whl\n",
      "Collecting pyparsing>=2.1.4\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/0c/fc2e007d9a992d997f04a80125b0f183da7fb554f1de701bbb70a8e7d479/pyparsing-2.4.5-py2.py3-none-any.whl (67kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 7.5MB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pyparsing, pydot\n",
      "Successfully installed pydot-1.4.1 pyparsing-2.4.5\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n",
    "!pip install scikit-learn\n",
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import pydot as pyd\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "keras.utils.vis_utils.pydot = pyd\n",
    "def visualize_model(model):\n",
    "  return SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = build_model(embedding_matrix)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_history = model.fit(\n",
    "#     [train_text, train_questions], \n",
    "#     train_target,\n",
    "#     epochs=2,\n",
    "#     validation_split=0.02,\n",
    "#     batch_size=1024\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splites=5\n",
    "skf = StratifiedKFold(n_splits=n_splites,random_state=666,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    24000300    input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_2 (SpatialDro (None, None, 300)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, None, 300)    0           embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, None, 200)    320800      spatial_dropout1d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, None, 300)    541200      spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 200)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 300)          0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500)          0           global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 300)          150300      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 300)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 300)          90300       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 300)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            301         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 25,103,201\n",
      "Trainable params: 1,102,901\n",
      "Non-trainable params: 24,000,300\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1506804 samples, validate on 30752 samples\n",
      "Epoch 1/2\n",
      "   2048/1506804 [..............................] - ETA: 8:23:41 - loss: 0.6086 - accuracy: 0.8477 "
     ]
    }
   ],
   "source": [
    "test_result=np.zeros(len(test))\n",
    "for train_index, _ in skf.split(train_text, train_target):\n",
    "    ans_,qus_=train_text[train_index],train_questions[train_index]\n",
    "    label = train_target[train_index]\n",
    "    model=get_model()\n",
    "    train_history = model.fit(\n",
    "        [ans_, qus_], \n",
    "        label,\n",
    "        epochs=2,\n",
    "        validation_split=0.02,\n",
    "        batch_size=1024\n",
    "    )\n",
    "    re=model.predict([test_text,test_questions])\n",
    "    test_result+=re\n",
    "    cleal_session()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
